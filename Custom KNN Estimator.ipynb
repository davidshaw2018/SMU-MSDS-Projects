{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from scipy.spatial.distance import euclidean, cosine, chebyshev, braycurtis\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_knn(BaseEstimator):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    My own implementation of KNN. The two parameters accepted are:\n",
    "    1. int - the number of neighbors K\n",
    "    2. function - the distance metric to use. The distance function must take in 2 numpy arrays and return a single distance. \n",
    "    \n",
    "    The algorithm used will be the brute force approach. \n",
    "    \n",
    "    Ideas taken from: \n",
    "    https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761\n",
    "    https://github.com/scikit-learn-contrib/project-template/blob/master/skltemplate/_template.py\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, n_neighbors=5, distance_func=euclidean):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.distance_func = distance_func\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        \n",
    "        \"\"\"\n",
    "        X and y must be numpy arrays\n",
    "        \"\"\"\n",
    "        \n",
    "        # Store training set as model objects\n",
    "        self.X_ = X\n",
    "        self.Y_ = Y\n",
    "        \n",
    "        # That's it for training. Since knn is a lazy algorithm, the only training it needs is to memorize the training data and its labels. \n",
    "        return(self)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict(self, X_test, **kwargs):\n",
    "        \n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        X_test - the evaluation set. Each instance in X_test will have distances calculated against each point in X_train\n",
    "        optional kwargs to pass to the distance function. \n",
    "        \"\"\"\n",
    "        \n",
    "        # Check that .fit has been called\n",
    "        # Caveat: X and Y must share a 1:1 mapping of indices\n",
    "        check_is_fitted(self, ['X_', 'Y_'])\n",
    "        \n",
    "        \n",
    "        # Initialize dictionary to store results\n",
    "        results = {}\n",
    "        \n",
    "        for i_test, inst in enumerate(X_test):\n",
    "            \n",
    "            # We need to find the k nearest neighbors for each instance of the training set to the query point inst\n",
    "            # Initialize temp dictionary to store results. Keyed by index of training set, and contains distance\n",
    "            \n",
    "            inst_dict = {}\n",
    "            \n",
    "            for i_train, query in enumerate(self.X_):\n",
    "                \n",
    "                # Calculate the distance\n",
    "                inst_dict[i_train] = self.distance_func(inst, query, **kwargs)\n",
    "                \n",
    "            # Extract the training indices for the K nearest neighbors by our specified distance metric\n",
    "            n_nearest = [k for k,v in sorted(inst_dict.items(), key=lambda x: x[1])[:self.n_neighbors]]\n",
    "            \n",
    "            # Take a vote!\n",
    "            y_labels = self.Y_[n_nearest]\n",
    "            \n",
    "            # Count frequences, select the highest count, and extract the value from the resultant tuple\n",
    "            # Note: If there is a tie, the first element is selected. This behavior is a little random by nature. \n",
    "            # Sklearn's KNN does the same thing, but the order of the elements may be different. \n",
    "            vote = collections.Counter(y_labels).most_common(1)[0][0]\n",
    "            \n",
    "            # Add the vote to our results dictionary\n",
    "            results[i_test] = vote\n",
    "            \n",
    "        # After looping, return an array of predictions\n",
    "        return np.array(list(results.values()))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test out our classifier, and see how close our results are to sklearn's version of KNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9550561797752809"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "our_knn = custom_knn(n_neighbors=5, distance_func=euclidean)\n",
    "sklearn_knn = KNeighborsClassifier(n_neighbors=5, algorithm='brute', metric='euclidean')\n",
    "\n",
    "our_knn.fit(wine.data, wine.target)\n",
    "sklearn_knn.fit(wine.data, wine.target)\n",
    "\n",
    "sum(our_knn.predict(wine.data) == sklearn_knn.predict(wine.data)) / wine.data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the same prediction results as sklearn's KNN on 95.5% of all entries in our dataset. \n",
    "\n",
    "We can use our custom classifier to do some actual data mining. As we would do with a built-in KNN module, we can perform some grid search to tune our hyperparameters, using simple accuracy as a scoring metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    4.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 981 ms, sys: 39.4 ms, total: 1.02 s\n",
      "Wall time: 12.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:   12.7s finished\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=8, shuffle=False),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=custom_knn(distance_func=<function euclidean at 0xa1c414b90>,\n",
       "                                  n_neighbors=5),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'distance_func': [<function euclidean at 0xa1c414b90>,\n",
       "                                           <function cosine at 0xa1c414d40>,\n",
       "                                           <function chebyshev at 0xa1c415170>,\n",
       "                                           <function braycurtis at 0xa1c415200>],\n",
       "                         'n_neighbors': [3, 5, 7, 9, 11, 13, 15]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Idea taken from https://nbviewer.jupyter.org/github/jakemdrew/StrandPy/blob/master/StrandClassifierV2%20GridSearchCV%20RDP%20CategoryScores.ipynb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# create cross validation iterator\n",
    "cv = StratifiedKFold(n_splits=10, random_state=8)\n",
    "knn_slate = custom_knn()\n",
    "\n",
    "parameters = { 'n_neighbors':[3,5,7,9,11,13,15]\n",
    "              ,'distance_func': [euclidean, cosine, chebyshev, braycurtis]\n",
    "             }\n",
    "\n",
    "grid_search = GridSearchCV(estimator=knn_slate\n",
    "                   , n_jobs=-1 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity in output messages\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv\n",
    "                   , scoring='accuracy')\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "grid_search.fit(wine.data, wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output, we see that overall GridSearch took about 12.7 seconds in total. In detail, the timing for each step is given as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean fit time is 6.043570382254463e-05s\n",
      "Mean score time is 0.17863712395940515s\n"
     ]
    }
   ],
   "source": [
    "def mean(x): # helper function for calculating array  means\n",
    "    return(sum(x) / len(x))\n",
    "\n",
    "print(\"Mean fit time is {}s\".format(mean(grid_search.cv_results_['mean_fit_time'])))\n",
    "print(\"Mean score time is {}s\".format(mean(grid_search.cv_results_['mean_score_time'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "custom_knn(distance_func=<function cosine at 0xa1c414d40>, n_neighbors=9)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best estimator then is a 9-nearest neighbors model using cosine distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest CV Mean Accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8146067415730337"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Highest CV Mean Accuracy')\n",
    "max(grid_search.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our highest CV mean accuracy is 81.4%, suggesting our classifier did quite well. We can also examine specificity/sensitivity as well to see if our model performs equally well among all labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86        59\n",
      "           1       0.72      0.58      0.64        71\n",
      "           2       0.46      0.58      0.51        48\n",
      "\n",
      "    accuracy                           0.67       178\n",
      "   macro avg       0.68      0.68      0.67       178\n",
      "weighted avg       0.69      0.67      0.68       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# code taken from https://nbviewer.jupyter.org/github/jakemdrew/StrandPy/blob/master/StrandClassifierV2%20GridSearchCV%20RDP%20CategoryScores.ipynb\n",
    "from sklearn.metrics import classification_report\n",
    "yhats = np.zeros(len(wine.target))\n",
    "\n",
    "#Perform 10 fold cv, saving all predictions \n",
    "for test, train in cv.split(wine.data,wine.target):\n",
    "    # Train and test on the one fold\n",
    "    knn = custom_knn(n_neighbors=9, distance_func=cosine)\n",
    "    knn.fit(wine.data[train],wine.target[train])\n",
    "    yhats[test] = knn.predict(wine.data[test])\n",
    "    \n",
    "    \n",
    "print(classification_report(y_true = wine.target, y_pred = yhats))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our accuracy statistics were inflated by the strong performance in classifying 0's, but our model did a poor job in correctly classifying wine type 2. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
